{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "notebook_path = input(\"Enter the path to your .ipynb file directory: \")\n",
        "if not os.path.exists(notebook_path): sys.exit(f\"Path {notebook_path} not found\")\n",
        "os.chdir(notebook_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkjRob9hPNQB",
        "outputId": "7d9a562a-cc34-4898-fc3e-2577e8b1ac89"
      },
      "id": "KkjRob9hPNQB",
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the path to your .ipynb file directory: /content/drive/MyDrive/LJMU_Data_XAI/TestGItCode/whitebox_mlops/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d2013085-73da-4021-abd1-ce0ac85597a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2013085-73da-4021-abd1-ce0ac85597a8",
        "outputId": "fce5e094-b467-4766-db57-375f7ce13afb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using label column: industry\n",
            "Using text column: full_summary\n",
            "Train data shape: (217, 12)\n",
            "Test data shape: (55, 12)\n",
            "Train data saved to: train_test_data/train_data.csv\n",
            "Test data saved to: train_test_data/test_data.csv\n"
          ]
        }
      ],
      "source": [
        "# create_test_data.py\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def create_test_data():\n",
        "    \"\"\"Create test data from balanced dataset\"\"\"\n",
        "\n",
        "    # Load balanced dataset\n",
        "    balanced_df = pd.read_csv(\"balanced_dataset/balanced_dataset.csv\")\n",
        "\n",
        "    # Auto-detect columns\n",
        "    label_candidates = ['label', 'category', 'class', 'target', 'industry', 'industry_name']\n",
        "    text_candidates = ['text', 'content', 'summary', 'description', 'full_summary']\n",
        "\n",
        "    label_col = None\n",
        "    text_col = None\n",
        "\n",
        "    for candidate in label_candidates:\n",
        "        if candidate in balanced_df.columns:\n",
        "            label_col = candidate\n",
        "            break\n",
        "\n",
        "    for candidate in text_candidates:\n",
        "        if candidate in balanced_df.columns:\n",
        "            text_col = candidate\n",
        "            break\n",
        "\n",
        "    if not label_col or not text_col:\n",
        "        print(\"Could not auto-detect columns\")\n",
        "        print(f\"Available columns: {balanced_df.columns.tolist()}\")\n",
        "        return False\n",
        "\n",
        "    print(f\"Using label column: {label_col}\")\n",
        "    print(f\"Using text column: {text_col}\")\n",
        "\n",
        "    # Split into train and test\n",
        "    train_df, test_df = train_test_split(\n",
        "        balanced_df,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=balanced_df[label_col]\n",
        "    )\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(\"train_test_data\", exist_ok=True)\n",
        "    os.makedirs(\"balanced_dataset\", exist_ok=True)\n",
        "\n",
        "    # Save train and test data\n",
        "    train_df.to_csv(\"train_test_data/train_data.csv\", index=False)\n",
        "    test_df.to_csv(\"train_test_data/test_data.csv\", index=False)\n",
        "    balanced_df.to_csv(\"balanced_dataset/balanced_dataset.csv\", index=False)\n",
        "\n",
        "    print(f\"Train data shape: {train_df.shape}\")\n",
        "    print(f\"Test data shape: {test_df.shape}\")\n",
        "    print(f\"Train data saved to: train_test_data/train_data.csv\")\n",
        "    print(f\"Test data saved to: train_test_data/test_data.csv\")\n",
        "\n",
        "    return True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f0b31ffd-10e4-4460-8ba5-b84b7b26be00",
      "metadata": {
        "id": "f0b31ffd-10e4-4460-8ba5-b84b7b26be00"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}